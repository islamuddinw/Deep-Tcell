{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdc24e8-bd90-407a-9eb6-c0e56ebf3893",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "KNN Pipeline for Tumor T-Cell Antigen Classification (Hardened)\n",
    "----------------------------------------------------------------\n",
    "- Loads a CSV dataset from local path.\n",
    "- Expects a binary label column (default: 'label').\n",
    "- Numeric feature columns only (non-numeric dropped with a warning).\n",
    "- 80/20 stratified train/holdout split.\n",
    "- Stratified K-Fold CV (auto-reduced if minority class is tiny).\n",
    "- Standardization inside each CV fold.\n",
    "- SMOTE applied **only** to training folds (and final train) with adaptive k_neighbors.\n",
    "- KNN classifier with ROC/AUC via predict_proba.\n",
    "- Metrics: ACC, SN (recall+), SP (specificity), AUC, MCC.\n",
    "- Saves: cv_fold_metrics.csv, cv_summary.csv, holdout_metrics.json,\n",
    "         confusion_matrix.png, roc_curve.png, holdout_predictions.csv, and model (joblib).\n",
    "\n",
    "Run examples:\n",
    "  python knn_pipeline.py --csv_path /path/to/data.csv --label_col label --out_dir ./knn_outputs\n",
    "  python knn_pipeline.py --csv_path data.csv --label_col status --label_map '{\"neg\":0,\"pos\":1}' \\\n",
    "                         --weights distance --n_neighbors 15\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import warnings\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    matthews_corrcoef,\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from joblib import dump\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ===============================\n",
    "# Helpers\n",
    "# ===============================\n",
    "\n",
    "def ensure_out_dir(path: str):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "def to_bool(x: str) -> bool:\n",
    "    return str(x).lower() in {\"1\", \"true\", \"yes\", \"y\", \"t\"}\n",
    "\n",
    "\n",
    "def safe_confusion_matrix(y_true: np.ndarray, y_pred: np.ndarray) -> np.ndarray:\n",
    "    labels = [0, 1]\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    if cm.shape != (2, 2):\n",
    "        fixed = np.zeros((2, 2), dtype=int)\n",
    "        fixed[: cm.shape[0], : cm.shape[1]] = cm\n",
    "        cm = fixed\n",
    "    return cm\n",
    "\n",
    "\n",
    "def compute_metrics(y_true: np.ndarray, y_prob: np.ndarray) -> Dict[str, float]:\n",
    "    y_pred = (y_prob >= 0.5).astype(int)\n",
    "    cm = safe_confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    acc = (tp + tn) / max(tp + tn + fp + fn, 1)\n",
    "    sn = tp / (tp + fn + 1e-9)\n",
    "    sp = tn / (tn + fp + 1e-9)\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, y_prob)\n",
    "    except ValueError:\n",
    "        auc = float(\"nan\")\n",
    "    mcc = matthews_corrcoef(y_true, y_pred) if (tp + tn + fp + fn) > 0 else 0.0\n",
    "    return {\"ACC\": acc, \"SN\": sn, \"SP\": sp, \"AUC\": auc, \"MCC\": mcc}\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm: np.ndarray, out_path: str, class_names: List[str]):\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    _ = ax.imshow(cm, interpolation=\"nearest\", cmap=\"Blues\")\n",
    "    ax.set_title(\"Confusion Matrix (KNN)\")\n",
    "    ax.set_xticks([0, 1]); ax.set_yticks([0, 1])\n",
    "    ax.set_xticklabels([f\"Predicted {c}\" for c in class_names], rotation=15, ha=\"right\")\n",
    "    ax.set_yticklabels([f\"Actual {c}\" for c in class_names])\n",
    "    for (i, j), val in np.ndenumerate(cm):\n",
    "        ax.text(j, i, f\"{int(val)}\", ha=\"center\", va=\"center\", fontsize=12)\n",
    "    fig.tight_layout(); fig.savefig(out_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def plot_roc(y_true: np.ndarray, y_score: np.ndarray, out_path: str, label=\"KNN\"):\n",
    "    try:\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "        auc = roc_auc_score(y_true, y_score)\n",
    "    except ValueError:\n",
    "        fpr, tpr, auc = [0, 1], [0, 1], float(\"nan\")\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    ax.plot(fpr, tpr, linewidth=2, label=f\"{label} (AUC={auc:.2f})\")\n",
    "    ax.plot([0, 1], [0, 1], \"--\", linewidth=1)\n",
    "    ax.set_xlabel(\"False Positive Rate\"); ax.set_ylabel(\"True Positive Rate\")\n",
    "    ax.set_title(\"ROC Curve (Holdout)\"); ax.legend(loc=\"lower right\")\n",
    "    fig.tight_layout(); fig.savefig(out_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def pick_numeric_features(df: pd.DataFrame, label_col: str) -> Tuple[pd.DataFrame, List[str]]:\n",
    "    feature_df = df.drop(columns=[label_col])\n",
    "    numeric_df = feature_df.select_dtypes(include=[np.number])\n",
    "    dropped = sorted(set(feature_df.columns) - set(numeric_df.columns))\n",
    "    if dropped:\n",
    "        print(f\"[Warn] Dropping non-numeric columns (not used as features): {dropped}\")\n",
    "    return numeric_df, list(numeric_df.columns)\n",
    "\n",
    "\n",
    "def parse_class_names(arg: Optional[str]) -> List[str]:\n",
    "    default = [\"Non-Tumor\", \"Tumor\"]\n",
    "    if not arg:\n",
    "        return default\n",
    "    parts = [p.strip() for p in arg.split(\",\")]\n",
    "    if len(parts) != 2:\n",
    "        print(f\"[Warn] --class_names expects two names. Using default {default}.\")\n",
    "        return default\n",
    "    return parts\n",
    "\n",
    "\n",
    "def minority_count(y: np.ndarray) -> int:\n",
    "    uniq, counts = np.unique(y, return_counts=True)\n",
    "    return int(counts.min()) if len(counts) else 0\n",
    "\n",
    "\n",
    "def best_smote(y: np.ndarray, seed: int) -> SMOTE:\n",
    "    m = minority_count(y)\n",
    "    k = max(1, min(5, m - 1))\n",
    "    return SMOTE(random_state=seed, k_neighbors=k)\n",
    "\n",
    "\n",
    "def auto_folds(y_tr: np.ndarray, desired: int = 5) -> int:\n",
    "    m = minority_count(y_tr)\n",
    "    return max(2, min(desired, m))\n",
    "\n",
    "\n",
    "def safe_n_neighbors(n_requested: int, n_train: int) -> int:\n",
    "    # KNN requires n_neighbors <= n_train; prefer odd k when possible\n",
    "    n = max(1, min(n_requested, max(1, n_train - 1)))\n",
    "    if n % 2 == 0 and n > 1:\n",
    "        n -= 1\n",
    "    return n\n",
    "\n",
    "# ===============================\n",
    "# Core Pipeline\n",
    "# ===============================\n",
    "\n",
    "def run(\n",
    "    csv_path: str,\n",
    "    label_col: str = \"label\",\n",
    "    label_map: str = None,\n",
    "    out_dir: str = \"./knn_outputs\",\n",
    "    use_smote: bool = True,\n",
    "    n_neighbors: int = 15,\n",
    "    weights: str = \"distance\",  # 'uniform' or 'distance'\n",
    "    metric: str = \"minkowski\",\n",
    "    p: int = 2,\n",
    "    class_names_arg: Optional[str] = None,\n",
    "    seed: int = 42,\n",
    "):\n",
    "    np.random.seed(seed)\n",
    "    ensure_out_dir(out_dir)\n",
    "\n",
    "    # Load data\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if label_col not in df.columns:\n",
    "        raise ValueError(f\"Label column '{label_col}' not found in CSV.\")\n",
    "\n",
    "    # Labels\n",
    "    y_raw = df[label_col]\n",
    "    if label_map:\n",
    "        mapping = json.loads(label_map)\n",
    "        y = y_raw.map(mapping)\n",
    "    else:\n",
    "        if pd.api.types.is_numeric_dtype(y_raw):\n",
    "            y = y_raw\n",
    "        else:\n",
    "            uniq = y_raw.dropna().unique()\n",
    "            if len(uniq) == 2:\n",
    "                keys = sorted(list(uniq), key=lambda v: str(v))\n",
    "                mapping = {keys[0]: 0, keys[1]: 1}\n",
    "                print(f\"[Info] Auto label_map inferred: {mapping}\")\n",
    "                y = y_raw.map(mapping)\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    \"Label column is non-numeric and has !=2 unique values. \"\n",
    "                    \"Provide --label_map, e.g. '{\\\"neg\\\":0,\\\"pos\\\":1}'.\"\n",
    "                )\n",
    "    if y.isna().any():\n",
    "        raise ValueError(\"Label mapping produced NaNs. Check --label_map and label values.\")\n",
    "    y = y.astype(int).values\n",
    "\n",
    "    # Features\n",
    "    X_df, feature_names = pick_numeric_features(df, label_col)\n",
    "    X = X_df.values.astype(np.float32)\n",
    "\n",
    "    print(f\"[Info] Data: X={X.shape}, positives={int(y.sum())}, negatives={int((y==0).sum())}\")\n",
    "\n",
    "    # Split\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=seed\n",
    "    )\n",
    "    print(f\"[Info] Holdout split => train={X_tr.shape[0]}, test={X_te.shape[0]}\")\n",
    "\n",
    "    # CV\n",
    "    n_splits = auto_folds(y_tr, desired=5)\n",
    "    if n_splits < 5:\n",
    "        print(f\"[Warn] Reduced CV folds to {n_splits} due to limited minority samples.\")\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    cv_metrics = []\n",
    "\n",
    "    for fold, (idx_tr, idx_va) in enumerate(skf.split(X_tr, y_tr), start=1):\n",
    "        X_tr_fold, X_va_fold = X_tr[idx_tr], X_tr[idx_va]\n",
    "        y_tr_fold, y_va_fold = y_tr[idx_tr], y_tr[idx_va]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_tr_fold_s = scaler.fit_transform(X_tr_fold)\n",
    "        X_va_fold_s = scaler.transform(X_va_fold)\n",
    "\n",
    "        # SMOTE\n",
    "        if use_smote:\n",
    "            sm = best_smote(y_tr_fold, seed)\n",
    "            X_tr_fold_s, y_tr_fold = sm.fit_resample(X_tr_fold_s, y_tr_fold)\n",
    "            print(f\"[Fold {fold}] After SMOTE: X={X_tr_fold_s.shape}, pos={int(y_tr_fold.sum())}\")\n",
    "\n",
    "        k = safe_n_neighbors(n_neighbors, n_train=len(X_tr_fold_s))\n",
    "        if k != n_neighbors:\n",
    "            print(f\"[Fold {fold}] Adjusted n_neighbors from {n_neighbors} to {k} due to small fold size.\")\n",
    "\n",
    "        clf = KNeighborsClassifier(\n",
    "            n_neighbors=k,\n",
    "            weights=weights,\n",
    "            metric=metric,\n",
    "            p=p,\n",
    "        )\n",
    "        clf.fit(X_tr_fold_s, y_tr_fold)\n",
    "\n",
    "        y_va_prob = clf.predict_proba(X_va_fold_s)[:, 1]\n",
    "        fold_m = compute_metrics(y_va_fold, y_va_prob)\n",
    "        cv_metrics.append(fold_m)\n",
    "        print(f\"[Fold {fold}] {fold_m}\")\n",
    "\n",
    "    # CV summary\n",
    "    cv_df = pd.DataFrame(cv_metrics)\n",
    "    cv_df.to_csv(os.path.join(out_dir, \"data.csv\"), index=False)\n",
    "    cv_summary = cv_df.agg([\"mean\", \"std\"]).T\n",
    "    cv_summary.to_csv(os.path.join(out_dir, \"cv_summary.csv\"))\n",
    "    print(\"\\n[CV Summary]\\n\", cv_summary)\n",
    "\n",
    "    # Final train & holdout eval\n",
    "    scaler_f = StandardScaler()\n",
    "    X_tr_s = scaler_f.fit_transform(X_tr)\n",
    "    X_te_s = scaler_f.transform(X_te)\n",
    "\n",
    "    if use_smote:\n",
    "        sm = best_smote(y_tr, seed)\n",
    "        X_tr_s, y_tr = sm.fit_resample(X_tr_s, y_tr)\n",
    "\n",
    "    k_final = safe_n_neighbors(n_neighbors, n_train=len(X_tr_s))\n",
    "    if k_final != n_neighbors:\n",
    "        print(f\"[Final] Adjusted n_neighbors from {n_neighbors} to {k_final} due to train size.\")\n",
    "\n",
    "    clf_f = KNeighborsClassifier(\n",
    "        n_neighbors=k_final,\n",
    "        weights=weights,\n",
    "        metric=metric,\n",
    "        p=p,\n",
    "    )\n",
    "    clf_f.fit(X_tr_s, y_tr)\n",
    "\n",
    "    y_te_prob = clf_f.predict_proba(X_te_s)[:, 1]\n",
    "    holdout = compute_metrics(y_te, y_te_prob)\n",
    "    with open(os.path.join(out_dir, \"holdout_metrics.json\"), \"w\") as f:\n",
    "        json.dump(holdout, f, indent=2)\n",
    "    print(\"\\n[Holdout Metrics]\\n\", holdout)\n",
    "\n",
    "    # Plots\n",
    "    y_te_pred = (y_te_prob >= 0.5).astype(int)\n",
    "    cm = safe_confusion_matrix(y_te, y_te_pred)\n",
    "    class_names = parse_class_names(class_names_arg)\n",
    "\n",
    "    plot_confusion_matrix(cm, os.path.join(out_dir, \"confusion_matrix.png\"), class_names)\n",
    "    plot_roc(y_te, y_te_prob, os.path.join(out_dir, \"roc_curve.png\"), label=\"KNN\")\n",
    "\n",
    "    # Save artifacts\n",
    "    artifact = {\n",
    "        \"scaler\": scaler_f,\n",
    "        \"knn\": clf_f,\n",
    "        \"feature_names\": feature_names,\n",
    "        \"label_col\": label_col,\n",
    "        \"class_names\": class_names,\n",
    "        \"params\": {\n",
    "            \"n_neighbors\": k_final,\n",
    "            \"weights\": weights,\n",
    "            \"metric\": metric,\n",
    "            \"p\": p,\n",
    "            \"use_smote\": use_smote,\n",
    "        },\n",
    "    }\n",
    "    dump(artifact, os.path.join(out_dir, \"knn_model.joblib\"))\n",
    "\n",
    "    # Save holdout predictions\n",
    "    pd.DataFrame({\"y_true\": y_te, \"y_prob\": y_te_prob, \"y_pred\": y_te_pred}).to_csv(\n",
    "        os.path.join(out_dir, \"holdout_predictions.csv\"), index=False\n",
    "    )\n",
    "\n",
    "    print(f\"[Done] Outputs saved to: {out_dir}\")\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# CLI\n",
    "# ===============================\n",
    "\n",
    "def build_argparser():\n",
    "    ap = argparse.ArgumentParser(description=\"KNN pipeline with SMOTE and ROC plotting (hardened).\")\n",
    "    ap.add_argument(\"--csv_path\", type=str, required=True, help=\"Path to local CSV file.\")\n",
    "    ap.add_argument(\"--label_col\", type=str, default=\"label\", help=\"Name of label column (0/1).\")\n",
    "    ap.add_argument(\"--label_map\", type=str, default=None, help='Optional JSON mapping, e.g. {\"neg\":0,\"pos\":1}')\n",
    "    ap.add_argument(\"--out_dir\", type=str, default=\"./knn_outputs\", help=\"Output directory.\")\n",
    "    ap.add_argument(\"--smote\", type=str, default=\"true\", help=\"Apply SMOTE on train folds (true/false).\")\n",
    "    ap.add_argument(\"--n_neighbors\", type=int, default=15, help=\"KNN n_neighbors (auto-adjusted if too large).\")\n",
    "    ap.add_argument(\"--weights\", type=str, default=\"distance\", choices=[\"uniform\", \"distance\"], help=\"KNN weights.\")\n",
    "    ap.add_argument(\"--metric\", type=str, default=\"minkowski\", help=\"Distance metric (e.g., minkowski, euclidean, manhattan).\")\n",
    "    ap.add_argument(\"--p\", type=int, default=2, help=\"Power parameter for Minkowski metric (p=1 manhattan, p=2 euclidean).\")\n",
    "    ap.add_argument(\"--class_names\", type=str, default=None, help='Comma-separated names for classes in plots, e.g. \"Non-Tumor,Tumor\"')\n",
    "    ap.add_argument(\"--seed\", type=int, default=42, help=\"Random seed.\")\n",
    "    return ap\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = build_argparser().parse_args()\n",
    "    run(\n",
    "        csv_path=args.csv_path,\n",
    "        label_col=args.label_col,\n",
    "        label_map=args.label_map,\n",
    "        out_dir=args.out_dir,\n",
    "        use_smote=to_bool(args.smote),\n",
    "        n_neighbors=args.n_neighbors,\n",
    "        weights=args.weights,\n",
    "        metric=args.metric,\n",
    "        p=args.p,\n",
    "        class_names_arg=args.class_names,\n",
    "        seed=args.seed,\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
